{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silvan's Code from preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import bz2 \n",
    "import pickle\n",
    "import _pickle as cPickle\n",
    "import os\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from numpy import cov\n",
    "from numpy.linalg import eig\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OUTPUT_Python_OpenAlex_Citation_and_Abstract_Data_C184779094.pbz2',\n",
       " 'OUTPUT_Python_OpenAlex_Citation_and_Abstract_Data_C97355855.pbz2',\n",
       " 'OUTPUT_Python_OpenAlex_Citation_and_Abstract_Data_C12554922.pbz2',\n",
       " 'OUTPUT_Python_OpenAlex_Citation_and_Abstract_Data_C111368507.pbz2',\n",
       " 'OUTPUT_Python_OpenAlex_Citation_and_Abstract_Data_C105795698.pbz2',\n",
       " 'OUTPUT_Python_OpenAlex_Citation_and_Abstract_Data_C153294291.pbz2',\n",
       " 'OUTPUT_Python_OpenAlex_Citation_and_Abstract_Data_C8058405.pbz2']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Read in Files\n",
    "\n",
    "path = os.getcwd()\n",
    "folder = '/Data'\n",
    "files = os.listdir(path + folder)\n",
    "\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_id</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>Discipline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://openalex.org/W2765252368</td>\n",
       "      <td>2017</td>\n",
       "      <td>C8058405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://openalex.org/W2135405592</td>\n",
       "      <td>2009</td>\n",
       "      <td>C8058405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://openalex.org/W2116007522</td>\n",
       "      <td>1971</td>\n",
       "      <td>C8058405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://openalex.org/W2908600692</td>\n",
       "      <td>2019</td>\n",
       "      <td>C8058405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://openalex.org/W3165125549</td>\n",
       "      <td>2021</td>\n",
       "      <td>C8058405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            work_id publication_year Discipline\n",
       "0  https://openalex.org/W2765252368             2017   C8058405\n",
       "1  https://openalex.org/W2135405592             2009   C8058405\n",
       "2  https://openalex.org/W2116007522             1971   C8058405\n",
       "3  https://openalex.org/W2908600692             2019   C8058405\n",
       "4  https://openalex.org/W3165125549             2021   C8058405"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['substorm expansion',\n",
       " 'wave frequencies',\n",
       " 'small substorm',\n",
       " 'expansion phase',\n",
       " 'small substorm expansion',\n",
       " 'substorm expansion phase',\n",
       " 'substorm onset',\n",
       " 'characteristics of the onset',\n",
       " 'physics of substorm',\n",
       " 'frequencies concurrent']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sender_ROR</th>\n",
       "      <th>Receiver_ROR</th>\n",
       "      <th>Year</th>\n",
       "      <th>Citations</th>\n",
       "      <th>Discipline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://ror.org/00hj8s172</td>\n",
       "      <td>https://ror.org/00hj8s172</td>\n",
       "      <td>1966</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>C8058405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://ror.org/042nb2s44</td>\n",
       "      <td>https://ror.org/00hj8s172</td>\n",
       "      <td>1966</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>C8058405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://ror.org/016st3p78</td>\n",
       "      <td>https://ror.org/02acart68</td>\n",
       "      <td>1967</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>C8058405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://ror.org/027m9bs27</td>\n",
       "      <td>https://ror.org/02acart68</td>\n",
       "      <td>1967</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>C8058405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://ror.org/02acart68</td>\n",
       "      <td>https://ror.org/02acart68</td>\n",
       "      <td>1967</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>C8058405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Sender_ROR               Receiver_ROR  Year  Citations  \\\n",
       "0  https://ror.org/00hj8s172  https://ror.org/00hj8s172  1966   1.000000   \n",
       "1  https://ror.org/042nb2s44  https://ror.org/00hj8s172  1966   1.000000   \n",
       "2  https://ror.org/016st3p78  https://ror.org/02acart68  1967   0.090909   \n",
       "3  https://ror.org/027m9bs27  https://ror.org/02acart68  1967   0.250000   \n",
       "4  https://ror.org/02acart68  https://ror.org/02acart68  1967   0.500000   \n",
       "\n",
       "  Discipline  \n",
       "0   C8058405  \n",
       "1   C8058405  \n",
       "2   C8058405  \n",
       "3   C8058405  \n",
       "4   C8058405  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load in cPickle file for Geophysics (OpenAlex ID C8058405)\n",
    "discipline = 'C8058405'\n",
    "# I had to change the \\ to a / because of Linux file paths\n",
    "Data_Packet = 'Data/OUTPUT_Python_OpenAlex_Citation_and_Abstract_Data_' + discipline + '.pbz2'\n",
    "\n",
    "f = bz2.BZ2File(Data_Packet, 'rb')\n",
    "paper_id_year_df = cPickle.load(f)\n",
    "corpus_dict = cPickle.load(f)\n",
    "citation_df = cPickle.load(f)\n",
    "\n",
    "# Object 1: dataframe with all the paper IDs and the year they were published: needed for the corpus_dict\n",
    "geophysics_paper_id_year_df = paper_id_year_df\n",
    "display(geophysics_paper_id_year_df.head())\n",
    "\n",
    "# Object 2: dictionary where the keys are the paper IDs and the values are a list containing the extracted terms\n",
    "# Structure: corpus_dict[Discipline_ID][paper_id] = [term1, term2, term3,...]: incl. eN and non-EN terms\n",
    "geophysics_corpus_dict = corpus_dict\n",
    "\n",
    "# sample call for single work\n",
    "display(geophysics_corpus_dict.get('C8058405').get('https://openalex.org/W2765252368'))\n",
    "\n",
    "# full call for all works\n",
    "#display(next(iter(geophysics_corpus_dict.items())))\n",
    "\n",
    "# Object 3: dataframe that's an edgelist between receiver RORs and sender RORs per year (= research organization registry)\n",
    "display(citation_df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landauer and Dumais Replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "YEAR = 2021\n",
    "EMBEDDING_DIMS = 10\n",
    "YEAR_COL = \"publication_year\"\n",
    "ID_COL = \"work_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function processes training data, establishing number IDs for each vocabulary word,\n",
    "# converting word sequence into ID sequence (input_as_ids), and providing dict\n",
    "# to map from word to its ID (word2id), and list to map from ID back to word (id2word)\n",
    "def process_training_data(tokens):\n",
    "    \"\"\"Taken from pset 2.\"\"\"\n",
    "    # Create the model's vocabulary and map to unique indices\n",
    "    word2id = {}\n",
    "    id2word = []\n",
    "    for word in tokens:\n",
    "        if word not in word2id:\n",
    "            id2word.append(word)\n",
    "            word2id[word] = len(id2word) - 1\n",
    "    # Convert string of text into string of IDs in a tensor for input to model\n",
    "    input_as_ids = []\n",
    "    for word in tokens:\n",
    "        input_as_ids.append(word2id[word])\n",
    "    # final_ids = torch.LongTensor(input_as_ids)\n",
    "    return input_as_ids,word2id,id2word\n",
    "\n",
    "\n",
    "def generate_mat(tokens, df):\n",
    "    \"\"\"\n",
    "    tokens: Iterable\n",
    "        set of individual tokens for corpus\n",
    "    df: pd.DataFrame\n",
    "        any subset of the paper_id_year_df\n",
    "    \"\"\"\n",
    "    input_as_ids, word2id, id2word = process_training_data(tokens)\n",
    "    num_unique_tokens = len(id2word)\n",
    "    num_docs = len(df[\"work_id\"])\n",
    "    mat = np.zeros((num_unique_tokens, num_docs))\n",
    "    \n",
    "    for token_idx in range(num_unique_tokens):\n",
    "        for doc_idx, work_id in enumerate(df[\"work_id\"]):\n",
    "            word = id2word[token_idx]\n",
    "            if word in geophysics_corpus_dict.get(work_id):\n",
    "                mat[token_idx, doc_idx] = 1\n",
    "\n",
    "    return mat\n",
    "\n",
    "def svd_dim_reduction(mat):\n",
    "    \"\"\"\n",
    "    TODO: replicate the Landauer and Dumais thing\n",
    "    \"\"\"\n",
    "    u, s, vh = np.linalg.svd(mat)\n",
    "    return None\n",
    "\n",
    "def pca_dim_reduction(mat):\n",
    "    \"\"\"\n",
    "    taken from https://machinelearningmastery.com/calculate-principal-component-analysis-scratch-python/\n",
    "    \"\"\"\n",
    "    # want to reduce on the rows, so take the transpose\n",
    "    A = mat.T\n",
    "    # calculate the mean of each column\n",
    "    M = mean(A.T, axis=1)\n",
    "    # center columns by subtracting column means\n",
    "    C = A - M\n",
    "    # calculate covariance matrix of centered matrix\n",
    "    V = cov(C.T)\n",
    "    # eigendecomposition of covariance matrix\n",
    "    values, vectors = eig(V)\n",
    "    # project data\n",
    "    P = vectors.T.dot(C.T)\n",
    "    return P.T, values\n",
    "\n",
    "def reduce_to_n_dimensions(mat, n):\n",
    "    \"\"\"\n",
    "    mat: np.Array\n",
    "        matrix being reduced\n",
    "    n: int\n",
    "        number of resulting dimensions\n",
    "    \"\"\"\n",
    "    pca_mat, eigenvalues = pca_dim_reduction(mat)\n",
    "    pca_mat = pca_mat.T\n",
    "    abs_eigenvalues = abs(eigenvalues)\n",
    "    sorted_abs = abs_eigenvalues.copy()\n",
    "    sorted_abs.sort()\n",
    "    threshold = sorted_abs[::-1][n]\n",
    "    most_significant = [1 if eigenvalue > threshold else 0 for eigenvalue in abs_eigenvalues]\n",
    "    new_mat = np.array([row for row, sig in zip(pca_mat, most_significant) if sig])\n",
    "    return new_mat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_year = geophysics_paper_id_year_df[geophysics_paper_id_year_df[YEAR_COL] == str(YEAR)]\n",
    "geophysics_corpus_dict = geophysics_corpus_dict.get(discipline)\n",
    "\n",
    "tokens = set()\n",
    "for work_id in df_year[ID_COL]:\n",
    "    new_tokens = set(geophysics_corpus_dict.get(work_id))\n",
    "    tokens = tokens.union(new_tokens)\n",
    "\n",
    "mat = generate_mat(tokens, df_year)\n",
    "mat = reduce_to_n_dimensions(mat, EMBEDDING_DIMS)\n",
    "# each column is an embedding of that particular\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01b886ef0f510f54f347081a8824a3cc2fa83f5cdfc36d594717f71ed3319b9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
