{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfe2fc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chenx\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import bz2 \n",
    "import pickle\n",
    "import _pickle as cPickle\n",
    "import os\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "\n",
    "#modified code for desktop usage\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0cd8d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OUTPUT_Python_OpenAlex_Citation_and_Abstract_Data_C105795698.pbz2',\n",
       " 'OUTPUT_Python_OpenAlex_Citation_and_Abstract_Data_C111368507.pbz2',\n",
       " 'OUTPUT_Python_OpenAlex_Citation_and_Abstract_Data_C12554922.pbz2',\n",
       " 'OUTPUT_Python_OpenAlex_Citation_and_Abstract_Data_C144024400.pbz2',\n",
       " 'OUTPUT_Python_OpenAlex_Citation_and_Abstract_Data_C153294291.pbz2',\n",
       " 'OUTPUT_Python_OpenAlex_Citation_and_Abstract_Data_C184779094.pbz2',\n",
       " 'OUTPUT_Python_OpenAlex_Citation_and_Abstract_Data_C8058405.pbz2',\n",
       " 'OUTPUT_Python_OpenAlex_Citation_and_Abstract_Data_C97355855.pbz2']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Read in Files\n",
    "\n",
    "path = os.getcwd()\n",
    "folder = '\\\\Data'\n",
    "files = os.listdir(path + folder)\n",
    "\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a779bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_id</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>Discipline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://openalex.org/W2775293320</td>\n",
       "      <td>2017</td>\n",
       "      <td>C12554922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://openalex.org/W2625325858</td>\n",
       "      <td>2017</td>\n",
       "      <td>C12554922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://openalex.org/W2478767193</td>\n",
       "      <td>2016</td>\n",
       "      <td>C12554922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://openalex.org/W2109735518</td>\n",
       "      <td>2012</td>\n",
       "      <td>C12554922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://openalex.org/W2037483496</td>\n",
       "      <td>2012</td>\n",
       "      <td>C12554922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            work_id publication_year Discipline\n",
       "0  https://openalex.org/W2775293320             2017  C12554922\n",
       "1  https://openalex.org/W2625325858             2017  C12554922\n",
       "2  https://openalex.org/W2478767193             2016  C12554922\n",
       "3  https://openalex.org/W2109735518             2012  C12554922\n",
       "4  https://openalex.org/W2037483496             2012  C12554922"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sender_ROR</th>\n",
       "      <th>Receiver_ROR</th>\n",
       "      <th>Year</th>\n",
       "      <th>Citations</th>\n",
       "      <th>Discipline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://ror.org/05apxxy63</td>\n",
       "      <td>https://ror.org/01y2jtd41</td>\n",
       "      <td>1940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>C12554922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://ror.org/00b30xv10</td>\n",
       "      <td>https://ror.org/00b30xv10</td>\n",
       "      <td>1941</td>\n",
       "      <td>4.5</td>\n",
       "      <td>C12554922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://ror.org/00hj8s172</td>\n",
       "      <td>https://ror.org/00b30xv10</td>\n",
       "      <td>1941</td>\n",
       "      <td>0.5</td>\n",
       "      <td>C12554922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://ror.org/00hx57361</td>\n",
       "      <td>https://ror.org/00b30xv10</td>\n",
       "      <td>1941</td>\n",
       "      <td>3.0</td>\n",
       "      <td>C12554922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://ror.org/00py81415</td>\n",
       "      <td>https://ror.org/00b30xv10</td>\n",
       "      <td>1941</td>\n",
       "      <td>2.0</td>\n",
       "      <td>C12554922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Sender_ROR               Receiver_ROR  Year  Citations  \\\n",
       "0  https://ror.org/05apxxy63  https://ror.org/01y2jtd41  1940        1.0   \n",
       "1  https://ror.org/00b30xv10  https://ror.org/00b30xv10  1941        4.5   \n",
       "2  https://ror.org/00hj8s172  https://ror.org/00b30xv10  1941        0.5   \n",
       "3  https://ror.org/00hx57361  https://ror.org/00b30xv10  1941        3.0   \n",
       "4  https://ror.org/00py81415  https://ror.org/00b30xv10  1941        2.0   \n",
       "\n",
       "  Discipline  \n",
       "0  C12554922  \n",
       "1  C12554922  \n",
       "2  C12554922  \n",
       "3  C12554922  \n",
       "4  C12554922  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load in cPickle file for Geophysics (OpenAlex ID C8058405)\n",
    "#discipline = 'C8058405'\n",
    "\n",
    "\n",
    "\n",
    "# load in cPickle file for Statistics (OpenAlex ID C105795698)\n",
    "#discipline = 'C105795698'\n",
    "\n",
    "# load in cPickle file for Oceanography (OpenAlex ID C111368507)\n",
    "#discipline = 'C111368507'\n",
    "\n",
    "# load in cPickle file for Biophysics (OpenAlex ID C12554922)\n",
    "discipline = 'C12554922'\n",
    "\n",
    "# load in cPickle file for Meteorology (OpenAlex ID C153294291)\n",
    "#discipline = 'C153294291'\n",
    "\n",
    "# load in cPickle file for Atomic physics (OpenAlex ID C184779094)\n",
    "#discipline = 'C184779094'\n",
    "\n",
    "# load in cPickle file for Thermodynamics (OpenAlex ID C97355855)\n",
    "#discipline = 'C97355855'\n",
    "\n",
    "Data_Packet = 'Data\\OUTPUT_Python_OpenAlex_Citation_and_Abstract_Data_' + discipline + '.pbz2'\n",
    "\n",
    "f = bz2.BZ2File(Data_Packet, 'rb')\n",
    "paper_id_year_df = cPickle.load(f)\n",
    "corpus_dict = cPickle.load(f)\n",
    "citation_df = cPickle.load(f)\n",
    "\n",
    "# Object 1: dataframe with all the paper IDs and the year they were published: needed for the corpus_dict\n",
    "geophysics_paper_id_year_df = paper_id_year_df\n",
    "display(geophysics_paper_id_year_df.head())\n",
    "\n",
    "# Object 2: dictionary where the keys are the paper IDs and the values are a list containing the extracted terms\n",
    "# Structure: corpus_dict[Discipline_ID][paper_id] = [term1, term2, term3,...]: incl. eN and non-EN terms\n",
    "geophysics_corpus_dict = corpus_dict\n",
    "\n",
    "# sample call for single work\n",
    "#display(geophysics_corpus_dict.get('C8058405').get('https://openalex.org/W2765252368'))\n",
    "\n",
    "# full call for all works\n",
    "#display(next(iter(geophysics_corpus_dict.items())))\n",
    "\n",
    "# Object 3: dataframe that's an edgelist between receiver RORs and sender RORs per year (= research organization registry)\n",
    "display(citation_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "753405e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocess Data for single field\n",
    "\n",
    "def reformat(dictionary):\n",
    "    '''\n",
    "    Takes the Object 2 dictionary and casts it into a dataframe\n",
    "    '''\n",
    "    # remove OpenAlex ID\n",
    "    field_dictionary = dictionary[1]\n",
    "    # reformat to list\n",
    "    field_list = list(map(list, field_dictionary.items()))\n",
    "    # cast into dataframe and rename columns\n",
    "    field_df = pd.DataFrame(field_list)\n",
    "    field_df = field_df.rename(columns = {0: 'work_id', 1: 'terms'})\n",
    "    \n",
    "    return field_df\n",
    "\n",
    "def add_year(field_df, paper_id_year_df):\n",
    "    '''\n",
    "    Takes the Object 2 dataframe and merges it with corresponding publication years from Object 1\n",
    "    '''\n",
    "    # merge the two dataframes\n",
    "    merged = pd.merge(field_df, paper_id_year_df, on ='work_id', how ='inner')\n",
    "    # reorder columns\n",
    "    columns = merged.columns.tolist()\n",
    "    columns = columns[-1:] + columns[-2:-1] + columns[:-2]\n",
    "    reordered = merged[columns]\n",
    "    \n",
    "    return reordered\n",
    "\n",
    "def lowercase(dataframe, column):\n",
    "    '''\n",
    "    takes a dataframe and lowercases everything within a specified column (column contents must be in a list of strings)\n",
    "    '''\n",
    "    dataframe[column] = dataframe[column].apply(lambda lst: [word.lower() for word in lst])\n",
    "    return dataframe\n",
    "\n",
    "def counts_per_document(reordered):\n",
    "    '''\n",
    "    Add number of documents, terms, unique terms, words, and unique words per document to the dataframe\n",
    "    '''\n",
    "    pd.set_option('mode.chained_assignment',None)\n",
    "    \n",
    "    reordered.loc[:,'NoD_pD'] = 1\n",
    "    reordered.loc[:,'NoT_pD'] = [len(cell) for cell in reordered['terms']]\n",
    "    reordered.loc[:,'NoUT_pD'] = [len(set(cell)) for cell in reordered['terms']]\n",
    "    reordered.loc[:,'NoW_pD'] = [sum([len(term.split()) for term in cell]) for cell in reordered['terms']]\n",
    "    reordered.loc[:,'NoUW_pD'] = [len(set([item for sublist in [term.split() for term in cell]\n",
    "                                           for item in sublist])) for cell in reordered['terms']]\n",
    "    \n",
    "    #display(reordered.describe())\n",
    "    return reordered\n",
    "\n",
    "def counts_per_year(reordered):\n",
    "    '''\n",
    "    Add number of documents, terms, unique terms, words, and unique words per year to the dataframe\n",
    "    '''\n",
    "    # aggregate documents per year and concatenate the list(s) of words\n",
    "    words = reordered.groupby('publication_year', as_index=False)['stemmed_tokens'].agg(lambda x: list(chain.from_iterable(x)))\n",
    "    # aggregate documents per year and count the number of documents\n",
    "    documents = reordered.groupby('publication_year', as_index=False).size()\n",
    "    # put the two dataframes together\n",
    "    grouped = pd.concat([words, documents['size']], axis = 1)\n",
    "    \n",
    "    # get counts of terms and words per year\n",
    "    grouped = grouped.rename(columns = {'size':'NoD'})\n",
    "    #grouped.loc[:,'NoT'] = [len(cell) for cell in grouped['terms']]\n",
    "    #grouped.loc[:,'NoUT'] = [len(set(cell)) for cell in grouped['terms']]\n",
    "    #grouped.loc[:,'NoW'] = [sum([len(term.split()) for term in cell]) for cell in grouped['words']]\n",
    "    #grouped.loc[:,'NoUW'] = [len(set([item for sublist in [term.split() for term in cell]\n",
    "                                      #for item in sublist])) for cell in grouped['words']]\n",
    "    grouped.loc[:,'NoS'] = [sum([len(term.split()) for term in cell]) for cell in grouped['stemmed_tokens']]\n",
    "    grouped.loc[:,'NoUS'] = [len(set([item for sublist in [term.split() for term in cell]\n",
    "                                      for item in sublist])) for cell in grouped['stemmed_tokens']]\n",
    "    \n",
    "    return grouped\n",
    "\n",
    "def split_string(dataframe, column):\n",
    "    '''\n",
    "    Split strings into substrings for a given column in the dataframe, creating the new column 'words'\n",
    "    '''\n",
    "    dataframe['words'] = dataframe[column].apply(lambda lst: [word for line in lst for word in line.split()])\n",
    "    return dataframe\n",
    "\n",
    "def remove_stopwords(dataframe, column):\n",
    "    '''\n",
    "    Remove stopwords from a list of words\n",
    "    '''\n",
    "    dataframe[column] = dataframe[column].apply(lambda lst: [word for word in lst if word not in stopwords])\n",
    "    return dataframe\n",
    "\n",
    "def wordcounter(wordlist, n):\n",
    "    '''\n",
    "    Counts terms/words within a list of strings, returns top n terms/words over time\n",
    "    Idea: Use output as illustrative example of how field progresses (validate with field-specific paper on paradigm shift)\n",
    "    '''\n",
    "    counts = {}\n",
    "    for word in wordlist:\n",
    "        if word in counts:\n",
    "            counts[word] += 1\n",
    "        else:\n",
    "            counts[word] = 1\n",
    "    \n",
    "    # convert dictionary to list of tuples\n",
    "    lst_counts = [(key, value) for key, value in counts.items()]\n",
    "    #sort in descending order\n",
    "    lst_counts.sort(key = lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return lst_counts[:n]\n",
    "\n",
    "def wordcounter_column(dataframe, column, n):\n",
    "    '''\n",
    "    Apply wordcounter() function to the entire column of a dataframe, returns a new column with top n items per year\n",
    "    '''\n",
    "    # define the new column name and fill it with nan values\n",
    "    if n != 1:\n",
    "        new_column = 'top ' + str(n) + ' ' + column\n",
    "    else:\n",
    "        new_column = 'top ' + str(n) + ' ' + column[:-1]\n",
    "    dataframe[new_column] = np.nan\n",
    "    \n",
    "    # loop through each row to get most frequent words\n",
    "    for index, row in dataframe.iterrows():\n",
    "        dataframe.iloc[index,dataframe.columns.get_loc(new_column)] = [wordcounter(row[column], n)]    \n",
    "    \n",
    "    # above line throws an error if outer brackets are removed, the followinf code flattens the nested list\n",
    "    # dataframe[new_column] =  dataframe[new_column].apply(np.ravel)\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "def wordcounter_abs_and_perc(dataframe, column, n, percentage):\n",
    "    '''\n",
    "    UPDATED VERSION OF WORDCOUNTER_COLUMN\n",
    "    \n",
    "    Apply wordcounter() function to the entire column of a dataframe, returns a new column with either\n",
    "    top n items per year or top n percent of items per year\n",
    "    \n",
    "    Function takes in a dataframe, a column name ('words' or 'terms'), n (either as whole number of cases or as percentage,\n",
    "    and boolean percentage ('YES' or 'NO' to indicate if number is top n or top n percent))\n",
    "    '''    \n",
    "    # define the new column name conditional on percentage\n",
    "    if percentage == 'YES':\n",
    "        # get number of unique words/terms based on given percentage\n",
    "        new_counter = 'NoU' + str(column[0]).capitalize() + ' (t' + str(n) + '%)'        \n",
    "        new_column = 't' + str(n) + '% of ' + column\n",
    "    elif n!= 1:\n",
    "        new_column = 't' + str(n) + ' ' + column\n",
    "    else:\n",
    "        new_column = 't' + str(n) + ' ' + column[:-1]\n",
    "        \n",
    "    # populate new_counter column with an integer of terms, if percentage given\n",
    "    if percentage == 'NO':\n",
    "        pass\n",
    "    #elif column == 'terms':\n",
    "        #dataframe[new_counter] = dataframe['NoUT'].multiply((n/100)).round().astype(np.int64)\n",
    "    #elif column == 'words':\n",
    "        #dataframe[new_counter] = dataframe['NoUW'].multiply((n/100)).round().astype(np.int64)\n",
    "    elif column == 'stemmed_tokens':\n",
    "        dataframe[new_counter] = dataframe['NoUS'].multiply((n/100)).round().astype(np.int64)\n",
    "        \n",
    "    # fill other column with nan values\n",
    "    dataframe[new_column] = np.nan\n",
    "    \n",
    "    # loop through each row to get most frequent words\n",
    "    for index, row in dataframe.iterrows():        \n",
    "        # condition for top n % of terms\n",
    "        if percentage == 'YES':\n",
    "            NoUX = dataframe.iloc[index,dataframe.columns.get_loc(new_counter)]\n",
    "            # account for edge case of NoUT being 0\n",
    "            if NoUX >= 1:\n",
    "                dataframe.iloc[index,dataframe.columns.get_loc(new_column)] = [wordcounter(row[column], NoUX)]\n",
    "            else:\n",
    "                dataframe.iloc[index,dataframe.columns.get_loc(new_column)] = np.nan\n",
    "        # condition for top n terms\n",
    "        else:\n",
    "            dataframe.iloc[index,dataframe.columns.get_loc(new_column)] = [wordcounter(row[column], n)]\n",
    "            \n",
    "        # above line throws an error if outer brackets are removed, the following code flattens the nested list\n",
    "        # dataframe[new_column] =  dataframe[new_column].apply(np.ravel)\n",
    "        \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a88fd946",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chenx\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "nltk.download('punkt')\n",
    "\n",
    "regex = r'[^a-z\\s]'\n",
    "\n",
    "def tokenize(text):\n",
    "    '''\n",
    "    Cleans, tokenizes + stems Pandas series of strings    \n",
    "    Returns pandas series of lists of tokens\n",
    "    '''\n",
    "    # Clean text with regex\n",
    "    clean = text.str.lower().str.replace(regex, '', regex=True)\n",
    "\n",
    "    # Anonymous tokenizer + stemmer functions\n",
    "    stop = nltk.corpus.stopwords.words('english')\n",
    "    tokenize = lambda text: [i for i in nltk.word_tokenize(text) if i not in stop]\n",
    "    stemmer = lambda tokens: [SnowballStemmer('english').stem(token) for token in tokens]\n",
    "\n",
    "    # Tokenize and stem clean text\n",
    "    tokens = clean.apply(tokenize)\n",
    "    stemmed_tokens = tokens.apply(stemmer)\n",
    "    \n",
    "    return stemmed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3df241c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = lowercase(add_year(reformat(next(iter(geophysics_corpus_dict.items()))), geophysics_paper_id_year_df), 'terms')\n",
    "\n",
    "# remove rows with empty lists\n",
    "b = a[a['terms'].map(lambda d: len(d)) > 0]\n",
    "\n",
    "# reformat row as strings\n",
    "b = b.astype({'terms':'string'})\n",
    "\n",
    "# split terms into words and stem\n",
    "b['stemmed_tokens'] = tokenize(b['terms'])\n",
    "\n",
    "# get ocunts per year for documents, words ,adn unique words (now no more terms because of stemming)\n",
    "b = counts_per_year(b)\n",
    "\n",
    "# top 10, 50, 100, 500 unique stemmed tokens\n",
    "c = wordcounter_abs_and_perc(b, 'stemmed_tokens', 10, 'NO')\n",
    "c = wordcounter_abs_and_perc(c, 'stemmed_tokens', 50, 'NO')\n",
    "c = wordcounter_abs_and_perc(c, 'stemmed_tokens', 100, 'NO')\n",
    "c = wordcounter_abs_and_perc(c, 'stemmed_tokens', 500, 'NO')\n",
    "\n",
    "# top 1%, 10%, 20%, 25 % of unique stemmed tokens\n",
    "c = wordcounter_abs_and_perc(c, 'stemmed_tokens', 1, 'YES')\n",
    "c = wordcounter_abs_and_perc(c, 'stemmed_tokens', 10, 'YES')\n",
    "c = wordcounter_abs_and_perc(c, 'stemmed_tokens', 20, 'YES')\n",
    "c = wordcounter_abs_and_perc(c, 'stemmed_tokens', 25, 'YES')\n",
    "\n",
    "# flatten list, calculate len, and divide by 2 since list contains words and their count (should max at 100)\n",
    "#c.loc[:,'t100 tokens count'] = c['t100 words'].apply(np.ravel).apply(len).div(2).astype(np.int64)\n",
    "# select relevant keys and set publication_year to index\n",
    "#d = c[['publication_year', 'NoD', 'NoT', 'NoUT', 'NoW', 'NoUW', 't100 words count', 't100 terms count', 'NoUW (t25%)',\n",
    "      #'NoUT (t25%)']]\n",
    "\n",
    "# fill NaN values with 0 (cases where terms do not meet threshold for meaningful results for a given top percentage)\n",
    "c.fillna(0)\n",
    "\n",
    "# convert publication year back to integer\n",
    "c = c.astype({'publication_year':'int'})\n",
    "\n",
    "d = c.set_index('publication_year')\n",
    "\n",
    "# create complete index without missing years\n",
    "new_index = list(range(int(min(d.index)), int(max(d.index)) + 1))\n",
    "\n",
    "# create empty dataframe with complete index\n",
    "e = pd.DataFrame(np.nan, index = new_index, columns = d.columns)\n",
    "\n",
    "e.index.name = 'publication_year'\n",
    "\n",
    "f = e.combine_first(d)\n",
    "f.reset_index(inplace=True)\n",
    "\n",
    "# display NA instead of full list of tokens (needed for usability as CSV for Felix)\n",
    "f['stemmed_tokens'] = 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc1d635d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_year</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>NoD</th>\n",
       "      <th>NoS</th>\n",
       "      <th>NoUS</th>\n",
       "      <th>t10 stemmed_tokens</th>\n",
       "      <th>t50 stemmed_tokens</th>\n",
       "      <th>t100 stemmed_tokens</th>\n",
       "      <th>t500 stemmed_tokens</th>\n",
       "      <th>NoUS (t1%)</th>\n",
       "      <th>t1% of stemmed_tokens</th>\n",
       "      <th>NoUS (t10%)</th>\n",
       "      <th>t10% of stemmed_tokens</th>\n",
       "      <th>NoUS (t20%)</th>\n",
       "      <th>t20% of stemmed_tokens</th>\n",
       "      <th>NoUS (t25%)</th>\n",
       "      <th>t25% of stemmed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1842</td>\n",
       "      <td>NA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[(singl, 6), (air, 5), (bronchial, 5), (ramif,...</td>\n",
       "      <td>[(singl, 6), (air, 5), (bronchial, 5), (ramif,...</td>\n",
       "      <td>[(singl, 6), (air, 5), (bronchial, 5), (ramif,...</td>\n",
       "      <td>[(singl, 6), (air, 5), (bronchial, 5), (ramif,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[(singl, 6)]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[(singl, 6), (air, 5)]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[(singl, 6), (air, 5)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1843</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1844</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1845</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1846</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2019</td>\n",
       "      <td>NA</td>\n",
       "      <td>13343.0</td>\n",
       "      <td>294355.0</td>\n",
       "      <td>9241.0</td>\n",
       "      <td>[[(cell, 7869), (protein, 3832), (membran, 334...</td>\n",
       "      <td>[[(cell, 7869), (protein, 3832), (membran, 334...</td>\n",
       "      <td>[[(cell, 7869), (protein, 3832), (membran, 334...</td>\n",
       "      <td>[[(cell, 7869), (protein, 3832), (membran, 334...</td>\n",
       "      <td>92.0</td>\n",
       "      <td>[[(cell, 7869), (protein, 3832), (membran, 334...</td>\n",
       "      <td>924.0</td>\n",
       "      <td>[[(cell, 7869), (protein, 3832), (membran, 334...</td>\n",
       "      <td>1848.0</td>\n",
       "      <td>[[(cell, 7869), (protein, 3832), (membran, 334...</td>\n",
       "      <td>2310.0</td>\n",
       "      <td>[[(cell, 7869), (protein, 3832), (membran, 334...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2020</td>\n",
       "      <td>NA</td>\n",
       "      <td>16042.0</td>\n",
       "      <td>353675.0</td>\n",
       "      <td>9992.0</td>\n",
       "      <td>[[(cell, 9252), (protein, 4577), (membran, 404...</td>\n",
       "      <td>[[(cell, 9252), (protein, 4577), (membran, 404...</td>\n",
       "      <td>[[(cell, 9252), (protein, 4577), (membran, 404...</td>\n",
       "      <td>[[(cell, 9252), (protein, 4577), (membran, 404...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[(cell, 9252), (protein, 4577), (membran, 404...</td>\n",
       "      <td>999.0</td>\n",
       "      <td>[[(cell, 9252), (protein, 4577), (membran, 404...</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>[[(cell, 9252), (protein, 4577), (membran, 404...</td>\n",
       "      <td>2498.0</td>\n",
       "      <td>[[(cell, 9252), (protein, 4577), (membran, 404...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2021</td>\n",
       "      <td>NA</td>\n",
       "      <td>16459.0</td>\n",
       "      <td>362228.0</td>\n",
       "      <td>10134.0</td>\n",
       "      <td>[[(cell, 9165), (protein, 4849), (membran, 400...</td>\n",
       "      <td>[[(cell, 9165), (protein, 4849), (membran, 400...</td>\n",
       "      <td>[[(cell, 9165), (protein, 4849), (membran, 400...</td>\n",
       "      <td>[[(cell, 9165), (protein, 4849), (membran, 400...</td>\n",
       "      <td>101.0</td>\n",
       "      <td>[[(cell, 9165), (protein, 4849), (membran, 400...</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>[[(cell, 9165), (protein, 4849), (membran, 400...</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>[[(cell, 9165), (protein, 4849), (membran, 400...</td>\n",
       "      <td>2534.0</td>\n",
       "      <td>[[(cell, 9165), (protein, 4849), (membran, 400...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2022</td>\n",
       "      <td>NA</td>\n",
       "      <td>7218.0</td>\n",
       "      <td>159473.0</td>\n",
       "      <td>6572.0</td>\n",
       "      <td>[[(cell, 3813), (protein, 2282), (membran, 161...</td>\n",
       "      <td>[[(cell, 3813), (protein, 2282), (membran, 161...</td>\n",
       "      <td>[[(cell, 3813), (protein, 2282), (membran, 161...</td>\n",
       "      <td>[[(cell, 3813), (protein, 2282), (membran, 161...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>[[(cell, 3813), (protein, 2282), (membran, 161...</td>\n",
       "      <td>657.0</td>\n",
       "      <td>[[(cell, 3813), (protein, 2282), (membran, 161...</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>[[(cell, 3813), (protein, 2282), (membran, 161...</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>[[(cell, 3813), (protein, 2282), (membran, 161...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2023</td>\n",
       "      <td>NA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>[[(bone, 6), (mesenchym, 5), (stem, 4), (rat, ...</td>\n",
       "      <td>[[(bone, 6), (mesenchym, 5), (stem, 4), (rat, ...</td>\n",
       "      <td>[[(bone, 6), (mesenchym, 5), (stem, 4), (rat, ...</td>\n",
       "      <td>[[(bone, 6), (mesenchym, 5), (stem, 4), (rat, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[[(bone, 6), (mesenchym, 5)]]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[[(bone, 6), (mesenchym, 5), (stem, 4), (rat, ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[[(bone, 6), (mesenchym, 5), (stem, 4), (rat, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     publication_year stemmed_tokens      NoD       NoS     NoUS  \\\n",
       "0                1842             NA      1.0      25.0      9.0   \n",
       "1                1843             NA      NaN       NaN      NaN   \n",
       "2                1844             NA      NaN       NaN      NaN   \n",
       "3                1845             NA      NaN       NaN      NaN   \n",
       "4                1846             NA      NaN       NaN      NaN   \n",
       "..                ...            ...      ...       ...      ...   \n",
       "177              2019             NA  13343.0  294355.0   9241.0   \n",
       "178              2020             NA  16042.0  353675.0   9992.0   \n",
       "179              2021             NA  16459.0  362228.0  10134.0   \n",
       "180              2022             NA   7218.0  159473.0   6572.0   \n",
       "181              2023             NA      2.0      46.0     18.0   \n",
       "\n",
       "                                    t10 stemmed_tokens  \\\n",
       "0    [(singl, 6), (air, 5), (bronchial, 5), (ramif,...   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "177  [[(cell, 7869), (protein, 3832), (membran, 334...   \n",
       "178  [[(cell, 9252), (protein, 4577), (membran, 404...   \n",
       "179  [[(cell, 9165), (protein, 4849), (membran, 400...   \n",
       "180  [[(cell, 3813), (protein, 2282), (membran, 161...   \n",
       "181  [[(bone, 6), (mesenchym, 5), (stem, 4), (rat, ...   \n",
       "\n",
       "                                    t50 stemmed_tokens  \\\n",
       "0    [(singl, 6), (air, 5), (bronchial, 5), (ramif,...   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "177  [[(cell, 7869), (protein, 3832), (membran, 334...   \n",
       "178  [[(cell, 9252), (protein, 4577), (membran, 404...   \n",
       "179  [[(cell, 9165), (protein, 4849), (membran, 400...   \n",
       "180  [[(cell, 3813), (protein, 2282), (membran, 161...   \n",
       "181  [[(bone, 6), (mesenchym, 5), (stem, 4), (rat, ...   \n",
       "\n",
       "                                   t100 stemmed_tokens  \\\n",
       "0    [(singl, 6), (air, 5), (bronchial, 5), (ramif,...   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "177  [[(cell, 7869), (protein, 3832), (membran, 334...   \n",
       "178  [[(cell, 9252), (protein, 4577), (membran, 404...   \n",
       "179  [[(cell, 9165), (protein, 4849), (membran, 400...   \n",
       "180  [[(cell, 3813), (protein, 2282), (membran, 161...   \n",
       "181  [[(bone, 6), (mesenchym, 5), (stem, 4), (rat, ...   \n",
       "\n",
       "                                   t500 stemmed_tokens  NoUS (t1%)  \\\n",
       "0    [(singl, 6), (air, 5), (bronchial, 5), (ramif,...         0.0   \n",
       "1                                                  NaN         NaN   \n",
       "2                                                  NaN         NaN   \n",
       "3                                                  NaN         NaN   \n",
       "4                                                  NaN         NaN   \n",
       "..                                                 ...         ...   \n",
       "177  [[(cell, 7869), (protein, 3832), (membran, 334...        92.0   \n",
       "178  [[(cell, 9252), (protein, 4577), (membran, 404...       100.0   \n",
       "179  [[(cell, 9165), (protein, 4849), (membran, 400...       101.0   \n",
       "180  [[(cell, 3813), (protein, 2282), (membran, 161...        66.0   \n",
       "181  [[(bone, 6), (mesenchym, 5), (stem, 4), (rat, ...         0.0   \n",
       "\n",
       "                                 t1% of stemmed_tokens  NoUS (t10%)  \\\n",
       "0                                                  NaN          1.0   \n",
       "1                                                  NaN          NaN   \n",
       "2                                                  NaN          NaN   \n",
       "3                                                  NaN          NaN   \n",
       "4                                                  NaN          NaN   \n",
       "..                                                 ...          ...   \n",
       "177  [[(cell, 7869), (protein, 3832), (membran, 334...        924.0   \n",
       "178  [[(cell, 9252), (protein, 4577), (membran, 404...        999.0   \n",
       "179  [[(cell, 9165), (protein, 4849), (membran, 400...       1013.0   \n",
       "180  [[(cell, 3813), (protein, 2282), (membran, 161...        657.0   \n",
       "181                                                NaN          2.0   \n",
       "\n",
       "                                t10% of stemmed_tokens  NoUS (t20%)  \\\n",
       "0                                         [(singl, 6)]          2.0   \n",
       "1                                                  NaN          NaN   \n",
       "2                                                  NaN          NaN   \n",
       "3                                                  NaN          NaN   \n",
       "4                                                  NaN          NaN   \n",
       "..                                                 ...          ...   \n",
       "177  [[(cell, 7869), (protein, 3832), (membran, 334...       1848.0   \n",
       "178  [[(cell, 9252), (protein, 4577), (membran, 404...       1998.0   \n",
       "179  [[(cell, 9165), (protein, 4849), (membran, 400...       2027.0   \n",
       "180  [[(cell, 3813), (protein, 2282), (membran, 161...       1314.0   \n",
       "181                      [[(bone, 6), (mesenchym, 5)]]          4.0   \n",
       "\n",
       "                                t20% of stemmed_tokens  NoUS (t25%)  \\\n",
       "0                               [(singl, 6), (air, 5)]          2.0   \n",
       "1                                                  NaN          NaN   \n",
       "2                                                  NaN          NaN   \n",
       "3                                                  NaN          NaN   \n",
       "4                                                  NaN          NaN   \n",
       "..                                                 ...          ...   \n",
       "177  [[(cell, 7869), (protein, 3832), (membran, 334...       2310.0   \n",
       "178  [[(cell, 9252), (protein, 4577), (membran, 404...       2498.0   \n",
       "179  [[(cell, 9165), (protein, 4849), (membran, 400...       2534.0   \n",
       "180  [[(cell, 3813), (protein, 2282), (membran, 161...       1643.0   \n",
       "181  [[(bone, 6), (mesenchym, 5), (stem, 4), (rat, ...          4.0   \n",
       "\n",
       "                                t25% of stemmed_tokens  \n",
       "0                               [(singl, 6), (air, 5)]  \n",
       "1                                                  NaN  \n",
       "2                                                  NaN  \n",
       "3                                                  NaN  \n",
       "4                                                  NaN  \n",
       "..                                                 ...  \n",
       "177  [[(cell, 7869), (protein, 3832), (membran, 334...  \n",
       "178  [[(cell, 9252), (protein, 4577), (membran, 404...  \n",
       "179  [[(cell, 9165), (protein, 4849), (membran, 400...  \n",
       "180  [[(cell, 3813), (protein, 2282), (membran, 161...  \n",
       "181  [[(bone, 6), (mesenchym, 5), (stem, 4), (rat, ...  \n",
       "\n",
       "[182 rows x 17 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15cd5e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normally convert to csv\n",
    "\n",
    "# f.to_csv('biophysics_df_304.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "446cd38d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nEXPLANATION\\n\\npublication_year denotes the year of publication, starting with the earliest available data. For years after the first\\nobservation for which data is not available, all entries are coded as NaN\\n\\nstemmed_tokens is the full list of stemmed tokens, including tokens that were used multiple times\\n\\nNoD counts then umber of documents\\nNoS counts the number of stemmed tokens\\nNoUS counts the number of unique stemmed tokens\\n\\nt10 stemmed_tokens, t50 stemmed_tokens, t100 stemmed_tokens, and t500 stemmed_tokens represent the top 10, 50, 100, and 500\\ntokens by frequency, in the format of [('token', frequency count), ('token2', frequency count), etc.]. For years with a\\nnumber of unique stemmed tokens below the top n, the full number of tokens will be displayed\\n(e.g., 11 tokens for t50 stemmed_tokens in 1832)\\n\\nNoUS (t1%), NoUS (t10%), NoUS (t20%), and NoUS (t25%) count the number of unique stemmed tokens in the top 1, 10, 20, and 25\\npercent. This can be 0 for smaller corpus sizes (e.g., top 1% for 11 unique stemmed tokens is 0, hence NoUS (t1%) is 0)\\n\\nt1% of stemmed_tokens, t10% of stemmed_tokens, t20% of stemmed_tokens, and t25% of stemmed_tokens list the actual tokens\\nwith their frequency of occurence, same as t10 stemmed_tokens (and subsequent columns) did before \\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "EXPLANATION\n",
    "\n",
    "publication_year denotes the year of publication, starting with the earliest available data. For years after the first\n",
    "observation for which data is not available, all entries are coded as NaN\n",
    "\n",
    "stemmed_tokens is the full list of stemmed tokens, including tokens that were used multiple times\n",
    "\n",
    "NoD counts then umber of documents\n",
    "NoS counts the number of stemmed tokens\n",
    "NoUS counts the number of unique stemmed tokens\n",
    "\n",
    "t10 stemmed_tokens, t50 stemmed_tokens, t100 stemmed_tokens, and t500 stemmed_tokens represent the top 10, 50, 100, and 500\n",
    "tokens by frequency, in the format of [('token', frequency count), ('token2', frequency count), etc.]. For years with a\n",
    "number of unique stemmed tokens below the top n, the full number of tokens will be displayed\n",
    "(e.g., 11 tokens for t50 stemmed_tokens in 1832)\n",
    "\n",
    "NoUS (t1%), NoUS (t10%), NoUS (t20%), and NoUS (t25%) count the number of unique stemmed tokens in the top 1, 10, 20, and 25\n",
    "percent. This can be 0 for smaller corpus sizes (e.g., top 1% for 11 unique stemmed tokens is 0, hence NoUS (t1%) is 0)\n",
    "\n",
    "t1% of stemmed_tokens, t10% of stemmed_tokens, t20% of stemmed_tokens, and t25% of stemmed_tokens list the actual tokens\n",
    "with their frequency of occurence, same as t10 stemmed_tokens (and subsequent columns) did before \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9146ab",
   "metadata": {},
   "source": [
    "# Start Felix's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82d06146",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is the processing unit copied from dataprocessing v3, MODIFIED for use here.\n",
    "\n",
    "# NEW IMPORTATIONS\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "\n",
    "\n",
    "# IMPORTATIONS\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.utils.exceptions import InvalidFileException as FileExc\n",
    "\n",
    "\n",
    "from decimal import *\n",
    "from scipy.special import softmax\n",
    "from scipy.stats import entropy\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "557e36d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input start year (inclusive): 2000\n",
      "Input end year (inclusive): 2020\n"
     ]
    }
   ],
   "source": [
    "# ___________________________________________________________\n",
    "# -----------------------------------------------------------\n",
    "#   NEW FILE + YEAR RANGE (START, YEARS) + START_ROW\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# FUNCTION: check that input is integer\n",
    "def check_integer(inp):\n",
    "    try:\n",
    "        inp = int(inp)\n",
    "        inp_is_int = True\n",
    "    except ValueError:\n",
    "        inp_is_int = False\n",
    "    return inp_is_int\n",
    "\n",
    "# New file with (1) Start year = START ; (2) No. of years/sheets = YEARS\n",
    "wb = Workbook()\n",
    "\n",
    "START = input(\"Input start year (inclusive): \")\n",
    "while True:\n",
    "    if check_integer(START):\n",
    "        START = int(START)\n",
    "        break\n",
    "    else:\n",
    "        START = input(\"Not integer. Input integer: \")\n",
    "\n",
    "YEARS = 0\n",
    "TERMIN = input(\"Input end year (inclusive): \")\n",
    "while True:\n",
    "    if check_integer(TERMIN):\n",
    "        YEARS = int(TERMIN) - START + 1\n",
    "        break\n",
    "    else:\n",
    "        TERMIN = input(\"Not integer. Input integer: \")\n",
    "\n",
    "# New workbook xlsx file name = old one + \"_processed.xlsx\"\n",
    "FILE_NAME = \"biophysics_processed\"\n",
    "\n",
    "# Create a sheet for each year\n",
    "for i in range(YEARS):\n",
    "    ws_temp = wb.create_sheet(str(START+i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd6f2131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___________________________________________________________\n",
    "# -----------------------------------------------------------\n",
    "#   LOAD ORIGINAL DATA FROM PANDAS DATAFRAME f\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# NEW: Start a separate Workbook for the original data (BEGIN templi + unpack)\n",
    "\n",
    "orig_wb = Workbook()\n",
    "orig_ws = orig_wb.active\n",
    "\n",
    "datasheet = orig_ws\n",
    "\n",
    "templi = list(dataframe_to_rows(f, index=False, header=True))\n",
    "\n",
    "#print(list(dataframe_to_rows(f, index=False, header=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08278496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(len(templi)):\\n    for j in range(len(templi[0])):\\n        orig_ws.cell(row=i+1, column=j+1, value=str(templi[i][j]))\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert templi to worksheet\n",
    "'''\n",
    "for i in range(len(templi)):\n",
    "    for j in range(len(templi[0])):\n",
    "        orig_ws.cell(row=i+1, column=j+1, value=str(templi[i][j]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eeb01e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> [('cell', 9252), ('p...4), ('infarct', 14)] \n",
      " <class 'tuple'> ('cell', 9252) ('infarct', 14)\n"
     ]
    }
   ],
   "source": [
    "# datasheet['Q179'].value\n",
    "print(\n",
    "    type(templi[179][16]),\n",
    "    str(templi[179][16][0])[:20]+'...'+str(templi[179][16][0])[-20:], '\\n',\n",
    "    \n",
    "    type(templi[179][16][0][0]),\n",
    "    templi[179][16][0][0],\n",
    "    templi[179][16][0][-1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b12b93b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpacking the double-nested lists\n",
    "for i in range(len(templi)):\n",
    "    for j in range(len(templi[0])):\n",
    "        if type(templi[i][j]) == list and len(templi[i][j]) == 1:\n",
    "            templi[i][j] = templi[i][j][0]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f152593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> [('cell', 9252), ('p...4), ('infarct', 14)] \n",
      " <class 'tuple'> ('cell', 9252)\n"
     ]
    }
   ],
   "source": [
    "#datasheet['Q179'].value  (unpacked)\n",
    "print(\n",
    "    type(templi[179][16]),\n",
    "    str(templi[179][16])[:20]+'...'+str(templi[179][16])[-20:], '\\n',\n",
    "    \n",
    "    type(templi[179][16][0]),\n",
    "    templi[179][16][0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a58fa19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODIFIED CODE FOR NOTEBOOK SHEET (templi instead of datasheet)\n",
    "\n",
    "# Identify start row\n",
    "START_ROW = 1\n",
    "\n",
    "def start_row_id(start_year, data_list):\n",
    "    for i in range(1, 195):\n",
    "        if data_list[i][0] == int(start_year):\n",
    "            start_row = i\n",
    "            break\n",
    "    return i\n",
    "\n",
    "START_ROW = start_row_id(START, templi)\n",
    "\n",
    "START_ROW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c214f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFIED CODE FOR NOTEBOOK SHEET (templi instead of datasheet)\n",
    "\n",
    "# Function to process a single cell (adapted for list-in-list format)\n",
    "def process_cell_data(row, col, data_list, wksht):\n",
    "    '''\n",
    "    row and col are int, data_list is a list.\n",
    "    Extract one cell from data_list > Deconstruct > Write in new file\n",
    "    '''\n",
    "    # Report on progress\n",
    "    print(f'r{row}c{col}', end=' ')\n",
    "    \n",
    "    # Extract a list of tuples\n",
    "    cell_list = data_list[row][col]\n",
    "    \n",
    "    # Iterate and extract from each tuple\n",
    "    for i in range(len(cell_list)):\n",
    "        # Add stem to one column (A)\n",
    "        wksht['A'+str(i+1)] = cell_list[i][0]\n",
    "        # Add absolute frequency to other column (B)\n",
    "        wksht['B'+str(i+1)] = cell_list[i][1]\n",
    "        # Add relative frequency (/NoD) to third column (C)\n",
    "        wksht['C'+str(i+1)] = cell_list[i][1] / data_list[row][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01588e88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r159c16 r160c16 r161c16 r162c16 r163c16 r164c16 r165c16 r166c16 r167c16 r168c16 r169c16 r170c16 r171c16 r172c16 r173c16 r174c16 r175c16 r176c16 r177c16 r178c16 r179c16 "
     ]
    }
   ],
   "source": [
    "# Back to Main code: for Notebook sheet, Q for top 25%\n",
    "for i in range(YEARS):\n",
    "    process_cell_data(row=i+START_ROW, col=16, data_list=templi, wksht=wb[str(START+i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef4f25b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Function for rounding 4/5 (half up)\n",
    "def rounding(number, precision):\n",
    "    '''\n",
    "    number float, precision float\n",
    "    '''\n",
    "    ret = float(\n",
    "        Decimal(str(number)).quantize(\n",
    "            Decimal(str(precision)), rounding=ROUND_HALF_UP\n",
    "            )\n",
    "        )\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a31f8e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.save(FILE_NAME+\".xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "065b3ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___________________________________________________________\n",
    "# -----------------------------------------------------------\n",
    "#   Calculate Shannon ENTROPY (base e)\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# Create new list for the entropies\n",
    "entropy_li = []\n",
    "\n",
    "def entropy_list_append(year, entr_li, wkbook):\n",
    "    col = list(wkbook[str(year)]['C'])\n",
    "    col_vals = np.array([i.value for i in col])\n",
    "    entr_rounded = rounding(entropy(col_vals), 0.001)\n",
    "    entr_li.append(entr_rounded)\n",
    "\n",
    "for d in range(YEARS):\n",
    "    entropy_list_append(START+d, entropy_li, wb)\n",
    "\n",
    "# Create new worksheet for entropy\n",
    "entr_ws = wb.create_sheet(\"entropy\", 0)\n",
    "\n",
    "entr_ws['A2'] = \"Entropy_0\"\n",
    "\n",
    "# Add the new entropies to the new worksheet\n",
    "for d in range(YEARS):\n",
    "    entr_ws.cell(row = 1, column = d+2, value = START+d)\n",
    "    entr_ws.cell(row = 2, column = d+2, value = entropy_li[d])\n",
    "\n",
    "\n",
    "wb.save(FILE_NAME+'.xlsx')\n",
    "# ------------------- FILE IS SAVED HERE ---------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4f12671",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_year</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>NoD</th>\n",
       "      <th>NoS</th>\n",
       "      <th>NoUS</th>\n",
       "      <th>t10 stemmed_tokens</th>\n",
       "      <th>t50 stemmed_tokens</th>\n",
       "      <th>t100 stemmed_tokens</th>\n",
       "      <th>t500 stemmed_tokens</th>\n",
       "      <th>NoUS (t1%)</th>\n",
       "      <th>t1% of stemmed_tokens</th>\n",
       "      <th>NoUS (t10%)</th>\n",
       "      <th>t10% of stemmed_tokens</th>\n",
       "      <th>NoUS (t20%)</th>\n",
       "      <th>t20% of stemmed_tokens</th>\n",
       "      <th>NoUS (t25%)</th>\n",
       "      <th>t25% of stemmed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1842</td>\n",
       "      <td>NA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[(singl, 6), (air, 5), (bronchial, 5), (ramif,...</td>\n",
       "      <td>[(singl, 6), (air, 5), (bronchial, 5), (ramif,...</td>\n",
       "      <td>[(singl, 6), (air, 5), (bronchial, 5), (ramif,...</td>\n",
       "      <td>[(singl, 6), (air, 5), (bronchial, 5), (ramif,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[(singl, 6)]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[(singl, 6), (air, 5)]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[(singl, 6), (air, 5)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1843</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1844</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1845</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1846</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2019</td>\n",
       "      <td>NA</td>\n",
       "      <td>13343.0</td>\n",
       "      <td>294355.0</td>\n",
       "      <td>9241.0</td>\n",
       "      <td>[[(cell, 7869), (protein, 3832), (membran, 334...</td>\n",
       "      <td>[[(cell, 7869), (protein, 3832), (membran, 334...</td>\n",
       "      <td>[[(cell, 7869), (protein, 3832), (membran, 334...</td>\n",
       "      <td>[[(cell, 7869), (protein, 3832), (membran, 334...</td>\n",
       "      <td>92.0</td>\n",
       "      <td>[[(cell, 7869), (protein, 3832), (membran, 334...</td>\n",
       "      <td>924.0</td>\n",
       "      <td>[[(cell, 7869), (protein, 3832), (membran, 334...</td>\n",
       "      <td>1848.0</td>\n",
       "      <td>[[(cell, 7869), (protein, 3832), (membran, 334...</td>\n",
       "      <td>2310.0</td>\n",
       "      <td>[[(cell, 7869), (protein, 3832), (membran, 334...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2020</td>\n",
       "      <td>NA</td>\n",
       "      <td>16042.0</td>\n",
       "      <td>353675.0</td>\n",
       "      <td>9992.0</td>\n",
       "      <td>[[(cell, 9252), (protein, 4577), (membran, 404...</td>\n",
       "      <td>[[(cell, 9252), (protein, 4577), (membran, 404...</td>\n",
       "      <td>[[(cell, 9252), (protein, 4577), (membran, 404...</td>\n",
       "      <td>[[(cell, 9252), (protein, 4577), (membran, 404...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[[(cell, 9252), (protein, 4577), (membran, 404...</td>\n",
       "      <td>999.0</td>\n",
       "      <td>[[(cell, 9252), (protein, 4577), (membran, 404...</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>[[(cell, 9252), (protein, 4577), (membran, 404...</td>\n",
       "      <td>2498.0</td>\n",
       "      <td>[[(cell, 9252), (protein, 4577), (membran, 404...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2021</td>\n",
       "      <td>NA</td>\n",
       "      <td>16459.0</td>\n",
       "      <td>362228.0</td>\n",
       "      <td>10134.0</td>\n",
       "      <td>[[(cell, 9165), (protein, 4849), (membran, 400...</td>\n",
       "      <td>[[(cell, 9165), (protein, 4849), (membran, 400...</td>\n",
       "      <td>[[(cell, 9165), (protein, 4849), (membran, 400...</td>\n",
       "      <td>[[(cell, 9165), (protein, 4849), (membran, 400...</td>\n",
       "      <td>101.0</td>\n",
       "      <td>[[(cell, 9165), (protein, 4849), (membran, 400...</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>[[(cell, 9165), (protein, 4849), (membran, 400...</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>[[(cell, 9165), (protein, 4849), (membran, 400...</td>\n",
       "      <td>2534.0</td>\n",
       "      <td>[[(cell, 9165), (protein, 4849), (membran, 400...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2022</td>\n",
       "      <td>NA</td>\n",
       "      <td>7218.0</td>\n",
       "      <td>159473.0</td>\n",
       "      <td>6572.0</td>\n",
       "      <td>[[(cell, 3813), (protein, 2282), (membran, 161...</td>\n",
       "      <td>[[(cell, 3813), (protein, 2282), (membran, 161...</td>\n",
       "      <td>[[(cell, 3813), (protein, 2282), (membran, 161...</td>\n",
       "      <td>[[(cell, 3813), (protein, 2282), (membran, 161...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>[[(cell, 3813), (protein, 2282), (membran, 161...</td>\n",
       "      <td>657.0</td>\n",
       "      <td>[[(cell, 3813), (protein, 2282), (membran, 161...</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>[[(cell, 3813), (protein, 2282), (membran, 161...</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>[[(cell, 3813), (protein, 2282), (membran, 161...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2023</td>\n",
       "      <td>NA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>[[(bone, 6), (mesenchym, 5), (stem, 4), (rat, ...</td>\n",
       "      <td>[[(bone, 6), (mesenchym, 5), (stem, 4), (rat, ...</td>\n",
       "      <td>[[(bone, 6), (mesenchym, 5), (stem, 4), (rat, ...</td>\n",
       "      <td>[[(bone, 6), (mesenchym, 5), (stem, 4), (rat, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[[(bone, 6), (mesenchym, 5)]]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[[(bone, 6), (mesenchym, 5), (stem, 4), (rat, ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[[(bone, 6), (mesenchym, 5), (stem, 4), (rat, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     publication_year stemmed_tokens      NoD       NoS     NoUS  \\\n",
       "0                1842             NA      1.0      25.0      9.0   \n",
       "1                1843             NA      NaN       NaN      NaN   \n",
       "2                1844             NA      NaN       NaN      NaN   \n",
       "3                1845             NA      NaN       NaN      NaN   \n",
       "4                1846             NA      NaN       NaN      NaN   \n",
       "..                ...            ...      ...       ...      ...   \n",
       "177              2019             NA  13343.0  294355.0   9241.0   \n",
       "178              2020             NA  16042.0  353675.0   9992.0   \n",
       "179              2021             NA  16459.0  362228.0  10134.0   \n",
       "180              2022             NA   7218.0  159473.0   6572.0   \n",
       "181              2023             NA      2.0      46.0     18.0   \n",
       "\n",
       "                                    t10 stemmed_tokens  \\\n",
       "0    [(singl, 6), (air, 5), (bronchial, 5), (ramif,...   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "177  [[(cell, 7869), (protein, 3832), (membran, 334...   \n",
       "178  [[(cell, 9252), (protein, 4577), (membran, 404...   \n",
       "179  [[(cell, 9165), (protein, 4849), (membran, 400...   \n",
       "180  [[(cell, 3813), (protein, 2282), (membran, 161...   \n",
       "181  [[(bone, 6), (mesenchym, 5), (stem, 4), (rat, ...   \n",
       "\n",
       "                                    t50 stemmed_tokens  \\\n",
       "0    [(singl, 6), (air, 5), (bronchial, 5), (ramif,...   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "177  [[(cell, 7869), (protein, 3832), (membran, 334...   \n",
       "178  [[(cell, 9252), (protein, 4577), (membran, 404...   \n",
       "179  [[(cell, 9165), (protein, 4849), (membran, 400...   \n",
       "180  [[(cell, 3813), (protein, 2282), (membran, 161...   \n",
       "181  [[(bone, 6), (mesenchym, 5), (stem, 4), (rat, ...   \n",
       "\n",
       "                                   t100 stemmed_tokens  \\\n",
       "0    [(singl, 6), (air, 5), (bronchial, 5), (ramif,...   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "177  [[(cell, 7869), (protein, 3832), (membran, 334...   \n",
       "178  [[(cell, 9252), (protein, 4577), (membran, 404...   \n",
       "179  [[(cell, 9165), (protein, 4849), (membran, 400...   \n",
       "180  [[(cell, 3813), (protein, 2282), (membran, 161...   \n",
       "181  [[(bone, 6), (mesenchym, 5), (stem, 4), (rat, ...   \n",
       "\n",
       "                                   t500 stemmed_tokens  NoUS (t1%)  \\\n",
       "0    [(singl, 6), (air, 5), (bronchial, 5), (ramif,...         0.0   \n",
       "1                                                  NaN         NaN   \n",
       "2                                                  NaN         NaN   \n",
       "3                                                  NaN         NaN   \n",
       "4                                                  NaN         NaN   \n",
       "..                                                 ...         ...   \n",
       "177  [[(cell, 7869), (protein, 3832), (membran, 334...        92.0   \n",
       "178  [[(cell, 9252), (protein, 4577), (membran, 404...       100.0   \n",
       "179  [[(cell, 9165), (protein, 4849), (membran, 400...       101.0   \n",
       "180  [[(cell, 3813), (protein, 2282), (membran, 161...        66.0   \n",
       "181  [[(bone, 6), (mesenchym, 5), (stem, 4), (rat, ...         0.0   \n",
       "\n",
       "                                 t1% of stemmed_tokens  NoUS (t10%)  \\\n",
       "0                                                  NaN          1.0   \n",
       "1                                                  NaN          NaN   \n",
       "2                                                  NaN          NaN   \n",
       "3                                                  NaN          NaN   \n",
       "4                                                  NaN          NaN   \n",
       "..                                                 ...          ...   \n",
       "177  [[(cell, 7869), (protein, 3832), (membran, 334...        924.0   \n",
       "178  [[(cell, 9252), (protein, 4577), (membran, 404...        999.0   \n",
       "179  [[(cell, 9165), (protein, 4849), (membran, 400...       1013.0   \n",
       "180  [[(cell, 3813), (protein, 2282), (membran, 161...        657.0   \n",
       "181                                                NaN          2.0   \n",
       "\n",
       "                                t10% of stemmed_tokens  NoUS (t20%)  \\\n",
       "0                                         [(singl, 6)]          2.0   \n",
       "1                                                  NaN          NaN   \n",
       "2                                                  NaN          NaN   \n",
       "3                                                  NaN          NaN   \n",
       "4                                                  NaN          NaN   \n",
       "..                                                 ...          ...   \n",
       "177  [[(cell, 7869), (protein, 3832), (membran, 334...       1848.0   \n",
       "178  [[(cell, 9252), (protein, 4577), (membran, 404...       1998.0   \n",
       "179  [[(cell, 9165), (protein, 4849), (membran, 400...       2027.0   \n",
       "180  [[(cell, 3813), (protein, 2282), (membran, 161...       1314.0   \n",
       "181                      [[(bone, 6), (mesenchym, 5)]]          4.0   \n",
       "\n",
       "                                t20% of stemmed_tokens  NoUS (t25%)  \\\n",
       "0                               [(singl, 6), (air, 5)]          2.0   \n",
       "1                                                  NaN          NaN   \n",
       "2                                                  NaN          NaN   \n",
       "3                                                  NaN          NaN   \n",
       "4                                                  NaN          NaN   \n",
       "..                                                 ...          ...   \n",
       "177  [[(cell, 7869), (protein, 3832), (membran, 334...       2310.0   \n",
       "178  [[(cell, 9252), (protein, 4577), (membran, 404...       2498.0   \n",
       "179  [[(cell, 9165), (protein, 4849), (membran, 400...       2534.0   \n",
       "180  [[(cell, 3813), (protein, 2282), (membran, 161...       1643.0   \n",
       "181  [[(bone, 6), (mesenchym, 5), (stem, 4), (rat, ...          4.0   \n",
       "\n",
       "                                t25% of stemmed_tokens  \n",
       "0                               [(singl, 6), (air, 5)]  \n",
       "1                                                  NaN  \n",
       "2                                                  NaN  \n",
       "3                                                  NaN  \n",
       "4                                                  NaN  \n",
       "..                                                 ...  \n",
       "177  [[(cell, 7869), (protein, 3832), (membran, 334...  \n",
       "178  [[(cell, 9252), (protein, 4577), (membran, 404...  \n",
       "179  [[(cell, 9165), (protein, 4849), (membran, 400...  \n",
       "180  [[(cell, 3813), (protein, 2282), (membran, 161...  \n",
       "181  [[(bone, 6), (mesenchym, 5), (stem, 4), (rat, ...  \n",
       "\n",
       "[182 rows x 17 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
