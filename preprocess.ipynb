{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfe2fc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Silvan Baier\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "import bz2 \n",
    "import pickle\n",
    "import _pickle as cPickle\n",
    "import os\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0cd8d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OUTPUT_Python_OpenAlex_Citation_and_Abstract_Data_C105795698.pbz2',\n",
       " 'OUTPUT_Python_OpenAlex_Citation_and_Abstract_Data_C111368507.pbz2',\n",
       " 'OUTPUT_Python_OpenAlex_Citation_and_Abstract_Data_C12554922.pbz2',\n",
       " 'OUTPUT_Python_OpenAlex_Citation_and_Abstract_Data_C153294291.pbz2',\n",
       " 'OUTPUT_Python_OpenAlex_Citation_and_Abstract_Data_C184779094.pbz2',\n",
       " 'OUTPUT_Python_OpenAlex_Citation_and_Abstract_Data_C8058405.pbz2',\n",
       " 'OUTPUT_Python_OpenAlex_Citation_and_Abstract_Data_C97355855.pbz2',\n",
       " 'Test']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Read in Files\n",
    "\n",
    "path = os.getcwd()\n",
    "folder = '\\\\Data'\n",
    "files = os.listdir(path + folder)\n",
    "\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a779bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_id</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>Discipline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://openalex.org/W2765252368</td>\n",
       "      <td>2017</td>\n",
       "      <td>C8058405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://openalex.org/W2135405592</td>\n",
       "      <td>2009</td>\n",
       "      <td>C8058405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://openalex.org/W2116007522</td>\n",
       "      <td>1971</td>\n",
       "      <td>C8058405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://openalex.org/W2908600692</td>\n",
       "      <td>2019</td>\n",
       "      <td>C8058405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://openalex.org/W3165125549</td>\n",
       "      <td>2021</td>\n",
       "      <td>C8058405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            work_id publication_year Discipline\n",
       "0  https://openalex.org/W2765252368             2017   C8058405\n",
       "1  https://openalex.org/W2135405592             2009   C8058405\n",
       "2  https://openalex.org/W2116007522             1971   C8058405\n",
       "3  https://openalex.org/W2908600692             2019   C8058405\n",
       "4  https://openalex.org/W3165125549             2021   C8058405"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['substorm expansion',\n",
       " 'wave frequencies',\n",
       " 'small substorm',\n",
       " 'expansion phase',\n",
       " 'small substorm expansion',\n",
       " 'substorm expansion phase',\n",
       " 'substorm onset',\n",
       " 'characteristics of the onset',\n",
       " 'physics of substorm',\n",
       " 'frequencies concurrent']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sender_ROR</th>\n",
       "      <th>Receiver_ROR</th>\n",
       "      <th>Year</th>\n",
       "      <th>Citations</th>\n",
       "      <th>Discipline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://ror.org/00hj8s172</td>\n",
       "      <td>https://ror.org/00hj8s172</td>\n",
       "      <td>1966</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>C8058405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://ror.org/042nb2s44</td>\n",
       "      <td>https://ror.org/00hj8s172</td>\n",
       "      <td>1966</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>C8058405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://ror.org/016st3p78</td>\n",
       "      <td>https://ror.org/02acart68</td>\n",
       "      <td>1967</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>C8058405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://ror.org/027m9bs27</td>\n",
       "      <td>https://ror.org/02acart68</td>\n",
       "      <td>1967</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>C8058405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://ror.org/02acart68</td>\n",
       "      <td>https://ror.org/02acart68</td>\n",
       "      <td>1967</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>C8058405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Sender_ROR               Receiver_ROR  Year  Citations  \\\n",
       "0  https://ror.org/00hj8s172  https://ror.org/00hj8s172  1966   1.000000   \n",
       "1  https://ror.org/042nb2s44  https://ror.org/00hj8s172  1966   1.000000   \n",
       "2  https://ror.org/016st3p78  https://ror.org/02acart68  1967   0.090909   \n",
       "3  https://ror.org/027m9bs27  https://ror.org/02acart68  1967   0.250000   \n",
       "4  https://ror.org/02acart68  https://ror.org/02acart68  1967   0.500000   \n",
       "\n",
       "  Discipline  \n",
       "0   C8058405  \n",
       "1   C8058405  \n",
       "2   C8058405  \n",
       "3   C8058405  \n",
       "4   C8058405  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load in cPickle file for Geophysics (OpenAlex ID C8058405)\n",
    "discipline = 'C8058405'\n",
    "Data_Packet = 'Data\\OUTPUT_Python_OpenAlex_Citation_and_Abstract_Data_' + discipline + '.pbz2'\n",
    "\n",
    "f = bz2.BZ2File(Data_Packet, 'rb')\n",
    "paper_id_year_df = cPickle.load(f)\n",
    "corpus_dict = cPickle.load(f)\n",
    "citation_df = cPickle.load(f)\n",
    "\n",
    "# Object 1: dataframe with all the paper IDs and the year they were published: needed for the corpus_dict\n",
    "geophysics_paper_id_year_df = paper_id_year_df\n",
    "display(geophysics_paper_id_year_df.head())\n",
    "\n",
    "# Object 2: dictionary where the keys are the paper IDs and the values are a list containing the extracted terms\n",
    "# Structure: corpus_dict[Discipline_ID][paper_id] = [term1, term2, term3,...]: incl. eN and non-EN terms\n",
    "geophysics_corpus_dict = corpus_dict\n",
    "\n",
    "# sample call for single work\n",
    "display(geophysics_corpus_dict.get('C8058405').get('https://openalex.org/W2765252368'))\n",
    "\n",
    "# full call for all works\n",
    "#display(next(iter(geophysics_corpus_dict.items())))\n",
    "\n",
    "# Object 3: dataframe that's an edgelist between receiver RORs and sender RORs per year (= research organization registry)\n",
    "display(citation_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "753405e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocess Data for single field\n",
    "\n",
    "def reformat(dictionary):\n",
    "    '''\n",
    "    Takes the Object 2 dictionary and casts it into a dataframe\n",
    "    '''\n",
    "    # remove OpenAlex ID\n",
    "    field_dictionary = dictionary[1]\n",
    "    # reformat to list\n",
    "    field_list = list(map(list, field_dictionary.items()))\n",
    "    # cast into dataframe and rename columns\n",
    "    field_df = pd.DataFrame(field_list)\n",
    "    field_df = field_df.rename(columns = {0: 'work_id', 1: 'terms'})\n",
    "    \n",
    "    return field_df\n",
    "\n",
    "def add_year(field_df, paper_id_year_df):\n",
    "    '''\n",
    "    Takes the Object 2 dataframe and merges it with corresponding publication years from Object 1\n",
    "    '''\n",
    "    # merge the two dataframes\n",
    "    merged = pd.merge(field_df, paper_id_year_df, on ='work_id', how ='inner')\n",
    "    # reorder columns\n",
    "    columns = merged.columns.tolist()\n",
    "    columns = columns[-1:] + columns[-2:-1] + columns[:-2]\n",
    "    reordered = merged[columns]\n",
    "    \n",
    "    return reordered\n",
    "\n",
    "def lowercase(dataframe, column):\n",
    "    '''\n",
    "    takes a dataframe and lowercases everything within a specified column (column contents must be in a list of strings)\n",
    "    '''\n",
    "    dataframe[column] = dataframe[column].apply(lambda lst: [word.lower() for word in lst])\n",
    "    return dataframe\n",
    "\n",
    "def counts_per_document(reordered):\n",
    "    '''\n",
    "    Add number of documents, terms, unique terms, words, and unique words per document to the dataframe\n",
    "    '''\n",
    "    pd.set_option('mode.chained_assignment',None)\n",
    "    \n",
    "    reordered.loc[:,'NoD_pD'] = 1\n",
    "    reordered.loc[:,'NoT_pD'] = [len(cell) for cell in reordered['terms']]\n",
    "    reordered.loc[:,'NoUT_pD'] = [len(set(cell)) for cell in reordered['terms']]\n",
    "    reordered.loc[:,'NoW_pD'] = [sum([len(term.split()) for term in cell]) for cell in reordered['terms']]\n",
    "    reordered.loc[:,'NoUW_pD'] = [len(set([item for sublist in [term.split() for term in cell]\n",
    "                                           for item in sublist])) for cell in reordered['terms']]\n",
    "    \n",
    "    #display(reordered.describe())\n",
    "    return reordered\n",
    "\n",
    "def counts_per_year(reordered):\n",
    "    '''\n",
    "    Add number of documents, terms, unique terms, words, and unique words per year to the dataframe\n",
    "    '''\n",
    "    # aggregate documents per year and concatenate the list(s) of words\n",
    "    words = reordered.groupby('publication_year', as_index=False)['terms'].agg(lambda x: list(chain.from_iterable(x)))\n",
    "    # aggregate documents per year and count the number of documents\n",
    "    documents = reordered.groupby('publication_year', as_index=False).size()\n",
    "    # put the two dataframes together\n",
    "    grouped = pd.concat([words, documents['size']], axis = 1)\n",
    "    \n",
    "    # get counts of terms and words per year\n",
    "    grouped = grouped.rename(columns = {'size':'NoD'})\n",
    "    grouped.loc[:,'NoT'] = [len(cell) for cell in grouped['terms']]\n",
    "    grouped.loc[:,'NoUT'] = [len(set(cell)) for cell in grouped['terms']]\n",
    "    grouped.loc[:,'NoW'] = [sum([len(term.split()) for term in cell]) for cell in grouped['terms']]\n",
    "    grouped.loc[:,'NoUW'] = [len(set([item for sublist in [term.split() for term in cell]\n",
    "                                      for item in sublist])) for cell in grouped['terms']]\n",
    "    \n",
    "    #display(grouped.describe())\n",
    "    return grouped\n",
    "\n",
    "def split_string(dataframe, column):\n",
    "    '''\n",
    "    Split strings into substrings for a given column in the dataframe, creating the new column 'words'\n",
    "    '''\n",
    "    dataframe['words'] = dataframe[column].apply(lambda lst: [word for line in lst for word in line.split()])\n",
    "    return dataframe\n",
    "\n",
    "def remove_stopwords(dataframe, column):\n",
    "    '''\n",
    "    Remove stopwords from a list of words\n",
    "    '''\n",
    "    dataframe[column] = dataframe[column].apply(lambda lst: [word for word in lst if word not in stopwords])\n",
    "    return dataframe\n",
    "\n",
    "def wordcounter(wordlist, n):\n",
    "    '''\n",
    "    Counts terms/words within a list of strings, returns top n terms/words over time\n",
    "    Idea: Use output as illustrative example of how field progresses (validate with field-specific paper on paradigm shift)\n",
    "    '''\n",
    "    counts = {}\n",
    "    for word in wordlist:\n",
    "        if word in counts:\n",
    "            counts[word] += 1\n",
    "        else:\n",
    "            counts[word] = 1\n",
    "    \n",
    "    # convert dictionary to list of tuples\n",
    "    lst_counts = [(key, value) for key, value in counts.items()]\n",
    "    #sort in descending order\n",
    "    lst_counts.sort(key = lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return lst_counts[:n]\n",
    "\n",
    "def wordcounter_column(dataframe, column, n):\n",
    "    '''\n",
    "    Apply wordcounter() function to the entire column of a dataframe, returns a new column with top n items per year\n",
    "    '''\n",
    "    # define the new column name and fill it with nan values\n",
    "    if n != 1:\n",
    "        new_column = 'top ' + str(n) + ' ' + column\n",
    "    else:\n",
    "        new_column = 'top ' + str(n) + ' ' + column[:-1]\n",
    "    dataframe[new_column] = np.nan\n",
    "    \n",
    "    # loop through each row to get most frequent words\n",
    "    for index, row in dataframe.iterrows():\n",
    "        dataframe.iloc[index,dataframe.columns.get_loc(new_column)] = [wordcounter(row[column], n)]    \n",
    "    \n",
    "    # above line throws an error if outer brackets are removed, the followinf code flattens the nested list\n",
    "    # dataframe[new_column] =  dataframe[new_column].apply(np.ravel)\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "def wordcounter_abs_and_perc(dataframe, column, n, percentage):\n",
    "    '''\n",
    "    UPDATED VERSION OF WORDCOUNTER_COLUMN\n",
    "    \n",
    "    Apply wordcounter() function to the entire column of a dataframe, returns a new column with either\n",
    "    top n items per year or top n percent of items per year\n",
    "    \n",
    "    Function takes in a dataframe, a column name ('words' or 'terms'), n (either as whole number of cases or as percentage,\n",
    "    and boolean percentage ('YES' or 'NO' to indicate if number is top n or top n percent))\n",
    "    '''    \n",
    "    # define the new column name conditional on percentage\n",
    "    if percentage == 'YES':\n",
    "        # get number of unique words/terms based on given percentage\n",
    "        new_counter = 'NoU' + str(column[0]).capitalize() + ' (t' + str(n) + '%)'\n",
    "        new_column = 't' + str(n) + '% of ' + column\n",
    "    elif n!= 1:\n",
    "        new_column = 't' + str(n) + ' ' + column\n",
    "    else:\n",
    "        new_column = 't' + str(n) + ' ' + column[:-1]\n",
    "        \n",
    "    # populate new_counter column with an integer of terms, if percentage given\n",
    "    if percentage == 'NO':\n",
    "        pass\n",
    "    elif column == 'terms':\n",
    "        dataframe[new_counter] = dataframe['NoUT'].multiply((n/100)).round().astype(np.int64)\n",
    "    elif column == 'words':\n",
    "        dataframe[new_counter] = dataframe['NoUW'].multiply((n/100)).round().astype(np.int64)\n",
    "        \n",
    "    # fill other column with nan values\n",
    "    dataframe[new_column] = np.nan\n",
    "    \n",
    "    # loop through each row to get most frequent words\n",
    "    for index, row in dataframe.iterrows():\n",
    "        # condition for top n % of terms\n",
    "        if percentage == 'YES':\n",
    "            NoUX = dataframe.iloc[index,dataframe.columns.get_loc(new_counter)]\n",
    "            # account for edge case of NoUT being 0\n",
    "            if NoUX >= 1:\n",
    "                dataframe.iloc[index,dataframe.columns.get_loc(new_column)] = [wordcounter(row[column], NoUX)]\n",
    "            else:\n",
    "                dataframe.iloc[index,dataframe.columns.get_loc(new_column)] = np.nan\n",
    "        # condition for top n terms\n",
    "        else:\n",
    "            dataframe.iloc[index,dataframe.columns.get_loc(new_column)] = [wordcounter(row[column], n)]\n",
    "            \n",
    "        # above line throws an error if outer brackets are removed, the following code flattens the nested list\n",
    "        # dataframe[new_column] =  dataframe[new_column].apply(np.ravel)\n",
    "        \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15cd5e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_year</th>\n",
       "      <th>terms</th>\n",
       "      <th>NoD</th>\n",
       "      <th>NoT</th>\n",
       "      <th>NoUT</th>\n",
       "      <th>NoW</th>\n",
       "      <th>NoUW</th>\n",
       "      <th>words</th>\n",
       "      <th>top 2 terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1832</td>\n",
       "      <td>[mean motion, mean motions, motions of the pla...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>16</td>\n",
       "      <td>[mean, motion, mean, motions, motions, planets...</td>\n",
       "      <td>[[(mean motion, 1), (mean motions, 1)]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1869</td>\n",
       "      <td>[secular change, change between the date, meas...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "      <td>18</td>\n",
       "      <td>[secular, change, change, date, measure, table...</td>\n",
       "      <td>[[(secular change, 1), (change between the dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1879</td>\n",
       "      <td>[external disturbing, bodily tides, considerat...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>[external, disturbing, bodily, tides, consider...</td>\n",
       "      <td>[[(external disturbing, 1), (bodily tides, 1)]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1884</td>\n",
       "      <td>[high pressure, high pressure steam, pressure ...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>[high, pressure, high, pressure, steam, pressu...</td>\n",
       "      <td>[[(high pressure, 1), (high pressure steam, 1)]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902</td>\n",
       "      <td>[diurnal inequality, times of occurrence, note...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>[diurnal, inequality, times, occurrence, note,...</td>\n",
       "      <td>[[(diurnal inequality, 1), (times of occurrenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2018</td>\n",
       "      <td>[unit boundaries, geostatistical integration, ...</td>\n",
       "      <td>180</td>\n",
       "      <td>1786</td>\n",
       "      <td>1708</td>\n",
       "      <td>4802</td>\n",
       "      <td>1094</td>\n",
       "      <td>[unit, boundaries, geostatistical, integration...</td>\n",
       "      <td>[[(magnetic field, 10), (geomagnetic field, 6)]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2019</td>\n",
       "      <td>[lunar craters, terrestrial craters, craters w...</td>\n",
       "      <td>294</td>\n",
       "      <td>2756</td>\n",
       "      <td>2594</td>\n",
       "      <td>7425</td>\n",
       "      <td>1404</td>\n",
       "      <td>[lunar, craters, terrestrial, craters, craters...</td>\n",
       "      <td>[[(upper mantle, 9), (magnetic field, 7)]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2020</td>\n",
       "      <td>[defective zones, observed possible, possible ...</td>\n",
       "      <td>563</td>\n",
       "      <td>5276</td>\n",
       "      <td>4769</td>\n",
       "      <td>14086</td>\n",
       "      <td>2049</td>\n",
       "      <td>[defective, zones, observed, possible, possibl...</td>\n",
       "      <td>[[(magnetic field, 24), (geomagnetic field, 16)]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2021</td>\n",
       "      <td>[ionospheric propagation, receiver amplitude, ...</td>\n",
       "      <td>465</td>\n",
       "      <td>4327</td>\n",
       "      <td>3927</td>\n",
       "      <td>11633</td>\n",
       "      <td>1832</td>\n",
       "      <td>[ionospheric, propagation, receiver, amplitude...</td>\n",
       "      <td>[[(magnetic field, 17), (electrical resistivit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2022</td>\n",
       "      <td>[anomaly in the ocean, temperature anomaly, eq...</td>\n",
       "      <td>405</td>\n",
       "      <td>3845</td>\n",
       "      <td>3534</td>\n",
       "      <td>10365</td>\n",
       "      <td>1691</td>\n",
       "      <td>[anomaly, ocean, temperature, anomaly, equator...</td>\n",
       "      <td>[[(magnetic field, 23), (electrical resistivit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   publication_year                                              terms  NoD  \\\n",
       "0              1832  [mean motion, mean motions, motions of the pla...    1   \n",
       "1              1869  [secular change, change between the date, meas...    1   \n",
       "2              1879  [external disturbing, bodily tides, considerat...    1   \n",
       "3              1884  [high pressure, high pressure steam, pressure ...    1   \n",
       "4              1902  [diurnal inequality, times of occurrence, note...    1   \n",
       "..              ...                                                ...  ...   \n",
       "76             2018  [unit boundaries, geostatistical integration, ...  180   \n",
       "77             2019  [lunar craters, terrestrial craters, craters w...  294   \n",
       "78             2020  [defective zones, observed possible, possible ...  563   \n",
       "79             2021  [ionospheric propagation, receiver amplitude, ...  465   \n",
       "80             2022  [anomaly in the ocean, temperature anomaly, eq...  405   \n",
       "\n",
       "     NoT  NoUT    NoW  NoUW  \\\n",
       "0     10    10     40    16   \n",
       "1     10    10     37    18   \n",
       "2     10    10     28    13   \n",
       "3     10    10     28    11   \n",
       "4     10    10     32    16   \n",
       "..   ...   ...    ...   ...   \n",
       "76  1786  1708   4802  1094   \n",
       "77  2756  2594   7425  1404   \n",
       "78  5276  4769  14086  2049   \n",
       "79  4327  3927  11633  1832   \n",
       "80  3845  3534  10365  1691   \n",
       "\n",
       "                                                words  \\\n",
       "0   [mean, motion, mean, motions, motions, planets...   \n",
       "1   [secular, change, change, date, measure, table...   \n",
       "2   [external, disturbing, bodily, tides, consider...   \n",
       "3   [high, pressure, high, pressure, steam, pressu...   \n",
       "4   [diurnal, inequality, times, occurrence, note,...   \n",
       "..                                                ...   \n",
       "76  [unit, boundaries, geostatistical, integration...   \n",
       "77  [lunar, craters, terrestrial, craters, craters...   \n",
       "78  [defective, zones, observed, possible, possibl...   \n",
       "79  [ionospheric, propagation, receiver, amplitude...   \n",
       "80  [anomaly, ocean, temperature, anomaly, equator...   \n",
       "\n",
       "                                          top 2 terms  \n",
       "0             [[(mean motion, 1), (mean motions, 1)]]  \n",
       "1   [[(secular change, 1), (change between the dat...  \n",
       "2     [[(external disturbing, 1), (bodily tides, 1)]]  \n",
       "3    [[(high pressure, 1), (high pressure steam, 1)]]  \n",
       "4   [[(diurnal inequality, 1), (times of occurrenc...  \n",
       "..                                                ...  \n",
       "76   [[(magnetic field, 10), (geomagnetic field, 6)]]  \n",
       "77         [[(upper mantle, 9), (magnetic field, 7)]]  \n",
       "78  [[(magnetic field, 24), (geomagnetic field, 16)]]  \n",
       "79  [[(magnetic field, 17), (electrical resistivit...  \n",
       "80  [[(magnetic field, 23), (electrical resistivit...  \n",
       "\n",
       "[81 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate sample data for visualization\n",
    "a = counts_per_year(lowercase(add_year(reformat(next(iter(geophysics_corpus_dict.items()))), geophysics_paper_id_year_df),\n",
    "                              'terms')) \n",
    "b = remove_stopwords(split_string(a, 'terms'), 'words')\n",
    "\n",
    "# top 100 unique words and terms, top 25 % of unique words and terms\n",
    "c = wordcounter_abs_and_perc(b, 'words', 100, 'NO')\n",
    "c = wordcounter_abs_and_perc(c, 'terms', 100, 'NO')\n",
    "c = wordcounter_abs_and_perc(c, 'words', 25, 'YES')\n",
    "c = wordcounter_abs_and_perc(c, 'terms', 25, 'YES')\n",
    "\n",
    "# flatten list, calculate len, and divide by 2 since list contains words and their count (should max at 100)\n",
    "c.loc[:,'t100 words count'] = c['t100 words'].apply(np.ravel).apply(len).div(2).astype(np.int64)\n",
    "c.loc[:,'t100 terms count'] = c['t100 terms'].apply(np.ravel).apply(len).div(2).astype(np.int64)\n",
    "\n",
    "# select relevant keys and set publication_year to index\n",
    "d = c[['publication_year', 'NoD', 'NoT', 'NoUT', 'NoW', 'NoUW', 't100 words count', 't100 terms count', 'NoUW (t25%)',\n",
    "      'NoUT (t25%)']]\n",
    "\n",
    "# reformat entire dataframe to integer datatype\n",
    "d = d.astype(int)\n",
    "\n",
    "d = d.set_index('publication_year')\n",
    "\n",
    "# create complete index without missing years\n",
    "new_index = list(range(int(min(d.index)), int(max(d.index)) + 1))\n",
    "\n",
    "# create empty dataframe with complete index\n",
    "e = pd.DataFrame(np.nan, index = new_index, columns = d.columns)\n",
    "\n",
    "e.index.name = 'publication_year'\n",
    "\n",
    "f = e.combine_first(d)\n",
    "f.reset_index(inplace=True)\n",
    "\n",
    "### Function Test\n",
    "x = counts_per_year(lowercase(add_year(reformat(next(iter(corpus_dict.items()))), paper_id_year_df),'terms')) \n",
    "y = remove_stopwords(split_string(x, 'terms'), 'words')\n",
    "\n",
    "wordcounter_column(y, 'terms', 2)\n",
    "\n",
    "# then write to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1131c088",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
